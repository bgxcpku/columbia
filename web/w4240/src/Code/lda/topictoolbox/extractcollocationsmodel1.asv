%% extract collocations from and place in topic-word distributions 

dataset = 3; % what dataset to work with? 1 = nips 2 = psych review

doshow = 1;  % 1 = show the most frequent collocations in data and model 
nshow = 50;  % how many collocation to show in list

%%
% load in the nips collocation data
if (dataset == 1)
    load 'nipscollocation'; % WW WO DS WS SI  
    % load in a single Gibbs sample from the LDACOL model
    load 'ldacol_nips'; % WP DP WC C ALPHA BETA GAMMA0 GAMMA1 DELTA SEED N Z
end

%%
% or load in the psych review collocation data
if (dataset == 2)
   load 'psychreviewcollocation'; % WW WO DS WS SI
   % load in a single Gibbs sample from the LDACOL model
   load 'ldacol_psychreview'; % WP DP WC C ALPHA BETA GAMMA0 GAMMA1 DELTA SEED N Z
end

%%
% or load in the psych review collocation data
if (dataset == 3)
   load 'tasacollocation'; % WW WO DS WS SI
   % load in a single Gibbs sample from the LDACOL model
   load 'ldacol_tasa'; % WP DP WC C ALPHA BETA GAMMA0 GAMMA1 DELTA SEED N Z
end


%%
% use the CreateCollocationTopics function to convert the single word vocabulary to new vocab
% with collocations; also update the wp and dp matrices with these new word
% indices
[ WPNEW , DPNEW , WONEW ] = CreateCollocationTopics( C , Z , WO , DS , WS , T );

% Put the most 7 likely words in each new topic in cell structure S
[S] = WriteTopics( WPNEW , BETA , WONEW , 7 , 0.7 );

%%
% Show the most likely words in the first ten topics
fprintf( '\n\nMost likely words in the first ten topics:\n' );

S( 1:10 )

%%
% Write the topics to a text file
if (dataset==1)
   WriteTopics( WPNEW , BETA , WONEW , 40 , 0.7 , 4 , 'topics_col_nips.txt' );
end

if (dataset==2)
   WriteTopics( WPNEW , BETA , WONEW , 40 , 0.7 , 4 , 'topics_col_psychreview.txt' );
end

if (dataset==3)
   WriteTopics( WPNEW , BETA , WONEW , 40 , 0.7 , 4 , 'topics_col_ta.txt' );
end

%%
% Show the most frequent collocations in data and model
if (doshow==1)
    % sort on decreasing frequency
    wh = find( C == 1 );
    w1 = WS( wh - 1 );
    w2 = WS( wh     );
    WWC = sparse( w2 , w1 , ones( size( w1 )));
    
    % all collocations in data
    [ ii,jj,ff ] = find( WWC );
    [ newff , index ] = sort( ff , 1 , 'descend' );
    fprintf( '\nFrequent collocations in model (frequency)\n' );
    for i=1:nshow
        w1 = jj( index( i ));
        w2 = ii( index( i ));
        f  = ff( index( i ));
        word1 = WO{ w1 };
        word2 = WO{ w2 };
        word = [ word1 '-' word2 ];
        fprintf( '%d %25s (%d)\n' , i , word , f );
    end

    % frequent collocations in data
    [ ii,jj,ff ] = find( WW );
    % sort on decreasing frequency
    [ newff , index ] = sort( ff , 1 , 'descend' );
    fprintf( '\n\nFrequent collocations in data  (frequency - cumulative frequency)\n' );
    fcum = 0;
    for i=1:nshow
        w1 = jj( index( i ));
        w2 = ii( index( i ));
        f  = ff( index( i ));
        fcum = fcum + f;
        word1 = WO{ w1 };
        word2 = WO{ w2 };
        word = [ word1 '-' word2 ];
        fprintf( '%d %25s (%d  -  %d)\n' , i , word , f , fcum );
    end
end
