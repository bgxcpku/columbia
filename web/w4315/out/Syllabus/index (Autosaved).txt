---
title: Syllabus
in_menu: true
routed_title: Syllabus
---

|---
| Lecture | Slides | Chapter | Extras |
|:-:|:-|:-|:-|:-|
| 01 | [Introduction](../Lectures/lecture_1/lecture_1.pdf "Slides") | 1 | |
| 02 | [Simple linear regression model; least squares; residuals](../Lectures/lecture_2/lecture_2.pdf "Slides") | 2 | |
| 03 | Introduction to MATLAB | | [demo.m](../Code/matlab_demo/general_matlab_demo.m) <br></br> [plot_gpa_fit.m](../Code/matlab_demo/plot_gpa_fit.m) <br></br> [my_regress.m](../Code/matlab_demo/my_regress.m)<br></br> [Getting started guide](http://www.mathworks.com/access/helpdesk/help/pdf_doc/matlab/getstart.pdf)| 04 | [Normal error regression model; maximum likelihood](../Lectures/lecture_3/lecture_3.pdf)
| 05 | [Proof of Gauss Markov Theorem, confidence intervals and hypothesis testing in the normal regression model. ](../Lectures/lecture_4/lecture4.pdf)
| 06 | [Convexity, Gradient Descent Methods, Convex Optimization](../Lectures/lecture_convexity/lecture_convexity.pdf)
| 07 | [Inference in Normal Regression Model](../Lectures/lecture_5/lecture_5.pdf) | 2.7-2.10
| 08 | [ANOVA](../Lectures/lecture_6/lecture_6.pdf) | | [Cochran's theorem](../Misc/Gut_Intermediate_Course_In_Probability_Excerpt.pdf)
| 09 | [Diagnostics and Remedial Measures](../Lectures/lecture_7/lecture_7.pdf) | 3 |
| 10 | [Remedial Measures and Transformations](../Lectures/lecture_8/lecture_8.pdf) | 4 |
| 11 | [Joint estimation, Bonferroni joint confidence intervals](../Lectures/lecture_9/lecture_9.pdf) | 5 |
| 12 | [?](../Lectures/lecture_10/lecture_10.pdf) | | Cheat sheets <br></br> [Matrix](http://www.cs.toronto.edu/~roweis/notes/matrixid.pdf), [Gaussian](http://www.cs.toronto.edu/~roweis/notes/gaussid.pdf), [Linear Algebra](http://www.math.upatras.gr/~vpiperig/Mul/Algebra.pdf)
| 13 | [Linear algebra review](../Lectures/lecture_11/lecture_11.pdf) ||
| 14 | [Multiple linear regression](../Lectures/lecture_11/lecture_11.pdf)
| 15 | More multiple linear regression
| 16 | [Proof of Cochran's Theorem](lecture_cochran/handwritten-notes.pdf)
| 17 | Midterm
| 18 |
| 19 | 
| 20 | 
| 21 | 
| 22 |
| 23 |
| 24 |
| 25 | 
| 26 |
| 27 |
| 28 |

<TR>
<TD>Th, Mar 11</TD> <TD>
Midterm Examination</TD> 
<TD> 
<!--<a href="final_project_instructions.pdf">Final Project Instructions</a>-->
</TD> </TR>


<TR>
<TD>Tu, Mar 16</TD> <TD>
No Class! Spring break!</TD> 
<TD></TD> </TR>

<TR>
<TD>Th, Mar 18</TD> <TD>
No Class! Spring break!
</TD> 
<TD></TD> </TR>

<TR>
<TD>Tu, Mar 23</TD><TD>
Midterm examination review. <br>
</TD> 
<TD></TD> </TR>

<TR>
<TD>Th, Mar 25</TD> <TD>
 Model selection.</TD> 
<TD><a href="variable_selection.pdf">Slides</a><br>
<a href="final_proj_instructions_Spr10.pdf"> Final Project Instruction</a> 
</TD> </TR>


<TR>
<TD>Tu, Mar 30</TD> <TD> Priciple Component Analysis
 </TD> 
<TD><a href="PCA/slides.pdf">Slides</a></TD> </TR>

<TR>
<TD>Th, Apr 1</TD> <TD>
Introduction to Bayesian inference.
 </TD> 
<TD>Read Gelman Chapter 11 <br>
<a href="Bayesian Inference/slides.pdf">Slides</a>
</TD> </TR>
<TR>
<TD>Tu, Apr 6</TD><TD>
Posterior simulation.
 </TD> 
<TD>Read Gelman Chapter 7<br> <a href="sampling.pdf">Slides</a></TD> </TR>

<TR>
<TD>Th, Apr 8</TD> <TD>
Posterior simulation cont.</TD> 
<TD></TD> </TR>


<TR>
<TD>Tu, Apr 13</TD><TD>
Posterior simulation cont.
 </TD> 
<TD></TD> </TR>

<TR>
<TD>Th, Apr 15</TD> <TD>
Neural Networks 
 </TD> 
<TD><a href="neural_network.pdf">Slides</a></TD> </TR>

<TR>
<TD>Tu, Apr 20</TD> <TD> Priciple Component Analysis
 </TD> 
<TD><a href="pca.pdf">Slides</a></TD> </TR>


<TR>
<TD>Th, Apr 22 </TD> <TD> Model selection
 </TD> 
<TD><a href="variable_selection.pdf">Slides</a></TD> </TR>

</TABLE> 
<!--
<TD>Tu, Apr 27 </TD> <TD> Final project reports due.
 </TD> 
<TD></TD> </TR>


<TR>
<TD>Th, Apr 29 </TD> <TD> Class project presentations 9am - 12pm.
 </TD>
<TD></TD> </TR>
</TABLE>


-->
