% !TEX root = deplump.tex
\section{Introduction}
\label{sec:introduction}

Deplump \citep{Gasthaus2010} is a general purpose, streaming lossless compressor based on a probabilistic model of discrete sequences called the sequence memoizer \citep{Wood2009}.   \citeauthor{Gasthaus2010} showed that although deplump is algorithmically similar to the PPM and CTW compression algorithms, particularly their unbounded context lengths variants \citep{Cleary1997,Willems1998}, the coherent probabilistic model underlying deplump gives it a consistent empirical advantage.  In particular, \citeauthor{Gasthaus2010} showed that deplump generally outperformed CTW  \citep{Willems2009}, PPMZ \citep{Peltola2002}, and PPM* \citep{Cleary1997} on the large Calgary corpus, the Canterbury corpus, Wikipedia, and Chinese text.  Deplump was shown to underperform in comparison to the PAQ family of compressors \citep{Mahoney2005}, but the point was made that deplump (or more specifically the sequence memoizer) could replace one or all of the mixed, finite-order Markov-model predictors included in PAQ.  

When introduced in \citep{Gasthaus2010}, deplump was reposed on a sequence memoizer whose space complexity was linear in the length of the input stream, rendering deplump inappropriate for stream compression.  Since then, constant space approximations to the sequence memoizer have emerged.  The sequence memoizer is an incremental method for hierarchically smoothing conditional distribution estimates when those conditional distributions are related to each other in a tree-shaped graphical model.  The space complexity of the sequence memoizer is a function of the number of instantiated nodes in the corresponding graphical model and the storage required at each node. \citeauthor{Bartlett2010} introduced an approximation to the sequence memoizer in which the number of nodes in the tree is of asymptotically constant order \citep{Bartlett2010}.  Unfortunately, in their work the storage requirement at each node grew as an uncharacterized but not-constant function of the input sequence length.  \citeauthor{Gasthaus2011} independently introduced a method for constraining the memory used at each node in the tree to be of constant order  \citep{Gasthaus2011} but did so in a way that requires the computational cost of inference to grow as a super-linear function of the length of the training sequence.

The primary contribution of this work is to marry these two separate bodies of work such that constant memory, linear time approximate inference in the sequence memoizer is achieved, thereby rendering deplump appropriate for streaming lossless compression applications without giving up the its inherent advantages while retaining.  Additionally, we have aimed to make a comprehensive algorithmic description of deplump available to those who might choose to implement deplump  for their own purposes.  This accompanies a reference implementation which is available on the \texttt{http://www.deplump.com/} website.