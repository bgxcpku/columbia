% !TEX root = deplump.tex
\section{Methodology}
\label{section:methodology}
\newcommand{\PY}{\ensuremath{\mathcal{P}\mathcal{Y}}}

In this section we first review the sequence memoizer model and the published approximate inference algorithms used in the deplump compressor.  We then discuss a new approximation necessary to achieve the asymptotic properties required for a streaming data setting.

\subsection{Review}

Note that a distribution $P$ over sequences can be factorized as $P(S = [s_0, s_1, \ldots, s_m]) = P(s_0)P_{[s_0]}(s_1)P_{[s_0,s_1]}(s_2) \ldots P_{[s_0,s_1,\ldots,s_{m-1}]}(s_m)$, where $P_u(s) = P(s | u)$.  The sequence memoizer jointly models these conditional distributions using a hierarchical Bayesian framework.  The hierarchy used to define the model makes use of the Pitman-Yor \citep{Pitman1997} distribution over distributions. If $P \sim \PY(d,c,G)$ then we say $P$ follows a Pitman-Yor distribution with discount parameter $d$, concentration parameter $c$, and mean distribution $G$.  The mean distribution $G$ can be understood as the average $P$ from this distribution, i.e. $\mathbb{E}(P(\sigma)) = G(\sigma)$ for $\sigma \in \Sigma$.  The discount parameter is a real value between 0 and 1.  If the discount is close to 1 it is an indication that $P$ is likely to be very close to $G$; d close to 0 indicates $P$ may vary significantly from $G$.  In the sequence memoizer the concentration parameters are restricted to 0 and will be omitted from the remaining discussion. If we define the suffix operator $\sigma$ on discrete sequences as $\sigma([s_0, s_1, \ldots, s_m]) = [s_1,s_2, \ldots, s_m])$ then we can write the sequence memoizer model as 
%
\[
\begin{array}{rcl}
	P_{[ ]} 	|	\delta_0 					& \sim & \PY(\delta_0,0,\mathcal{U}_{\Sigma})\\
	P_{u} 	| 	\delta_{|u|}, P_{\sigma(u)} 	& \sim & \PY(\delta_{|u|}, 0, P_{\sigma(u)}) \\
	s_n 		|  	P_{[s_0, s_1, \ldots, s_{n-1}] }	& \sim & P_{[s_0, s_1, \ldots, s_{n-1}] }
\end{array}
\]
%
\noindent where $\mathcal{U}_{\Sigma}$ is the uniform distribution over $\Sigma$.  The hierarchy used in the model smooths each conditional distribution $P_u$ towards a related, more general distribution $P_{\sigma(u)}$.  Intuitively the hierarchy indicates that the most recent context is the most informative for modeling the conditional distributions.

Given a model and observed data,  the task of inference is to learn likely values of the latent parameters.  The latent parameters of the sequence memoizer are  $\mathcal{G} = \{P_u \ | \ u \in \Sigma^{+} \}$ and $\delta_n$ for $n \geq 0$.  While $| \mathcal{G}| = \infty$, \citep{Wood2009} show that inference only requires computation on a set $\mathcal{H_\mathcal{S}} \subset \mathcal{G}$ for any finite training sequence $\mathcal{S}$ such that $|\mathcal{H}_\mathcal{S} | \leq 2 |\mathcal{S}|$.  Furthermore, they parameterize the discounts such that $\delta_n$ is a function of $\{\delta_0, \delta_1, \ldots, \delta_{10} \}$ for $n \geq 0$.   Unfortunately the linear bound on $|\mathcal{H}_\mathcal{S}|$ makes using the model intractable for streaming sequences. \citep{Bartlett2010} and \citep{Gasthaus2010} demonstrate that approximate inference using a single particle filter and a pruning scheme yields results comparable to the full model while maintaining a constant bound on$| \mathcal{H}_\mathcal{S}| $ for arbitrary length sequences $S \in \Sigma^{+}$.  Finally, \cite{Gasthaus2011} show that computation on $\mathcal{H}$ requires maintaining at most most $2|\Sigma| |\mathcal{H}|$ unique counts.  Combined these results comprise an inference technique which has a constant memory upper bound.

%Inference in the model is performed using a compressed representation in which only two counts for each symbol need to be maintained for a subset of the conditional distributions.  We will refer to this subset at element $t$ of the sequence as $\mathcal{H}$.  The cardinality of $\mathcal{H}$ grows linearly in the length of the sequence.  Bayesian inference is typically performed by averaging over the posterior distributions of parameters, but \cite{Gasthaus2010} demonstrate that using a single particle approximation yields excellent empirical results. \cite{Bartlett2010}  show that by making some independence assumptions the approximation can be extended and the cardinality of $\mathcal{H}$ can be bounded from above to provide a constant space inference procedure without much loss in  empirical performance.
%
\subsection{Approximation}

The inference procedure requires maintaining counts $c^P_\sigma,t^P_\sigma$ for each $P_u \in \mathcal{H}$ and $i \in \Sigma$.  The counts $c_{\sigma_i}$ grow as a linear function of the stream length.  Unfortunately the computation required to update the model is only bounded above by $K \max_{P \in \mathcal{H}, \sigma \in \Sigma} \{ c^P_\sigma \}$.  Therefore, to make the algorithm computationally tractable with arbitrary length sequences there must be an upper bound on $c^P_\sigma$.  

The counts $c_{\sigma}$ can be roughly thought of as counts in the estimation of a discrete distribution. If the total count $c$ is high relative to the dimension of the distribution then we can consider the distribution well estimated.  Intuitively once $c$ is high enough, bounding it will not effect the estimate much.  This intuition also suggests that the best way to decrement the counts is uniformly at random, an idea also supported in the \citep{Bartlett2010}.  Care is taken in deplump to extend the idea of a uniform deletion process to the counts $t_{\sigma}$ which is necessary because of the Pitman-Yor distributions in the sequence memoizer model.







