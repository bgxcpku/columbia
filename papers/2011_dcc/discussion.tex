% !TEX root = deplump.tex
\section{Discussion}
\label{sec:discussion}

In this paper we developed a new streaming variant of deplump.  We showed that the approximations introduced to make deplump stream-capable had almost no effect on compression performance relative to batch deplump, meaning that streaming deplump likewise outperforms unbounded context CTW, PPMZ, among others.  It remains the case that streaming deplump could be integrated into the PAQ family of compressors with the probable effect of improving its performance. 
%We empirically demonstrated that streaming deplump continues to improve as the stream length increases up to 1,000Mb.  Furthermore, we show that a reasonable bound on the total count in each suffix tree node has no effect on compression performance. We demonstrate that the depth of the tree can be a fixed low constant (10 - 32) without adverse effect on performance and we note that the algorithm performs better on long sequences when the number of nodes in the tree ($L$) is set high ($10^6$ or $10^7$).

%There are both theoretical and empirical questions to pursue in future work.  Of theoretical interest is the exploration of more expressive graphical models. Useful extensions might be made either by introducing sharing structures other than suffix trees, or by considering latent distributed (feature) representations of the stochastic generative process.  We would also like a more explicit mathematical characterization of how the approximations we make effect the inference procedure.  On the empirical side 
%Future work includes expanding the experimentation to include studies of compressing other datatypes.  We intend to purse PAQ-like model mixing.  