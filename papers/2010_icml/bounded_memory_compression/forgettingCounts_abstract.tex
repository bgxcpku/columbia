\begin{abstract} 
We propose a hierarchical Bayesian nonparametric model for discrete sequence data that can be represented in constant space and estimated incrementally in linear time.  The resulting estimation procedure can be viewed as either approximate inference of a model which grows linearly in space or as exact inference of a sequence of dependent nonparametric distributions.  We devise two proposal distributions for our estimation procedure corresponding to the two interpretations, a random deletion scheme and a greedy deletion scheme.  When tested on general compression corpora both proposals approach the performance of linear space methods while using significantly less memory, as well as outperforming both finite-depth models with the same memory bounds and standard compression methods.
\end{abstract} 