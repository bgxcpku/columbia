\section{A Generative Model for PDFAs}

We assume that $Q$, $\Sigma$ and $q_0$ are known, and define a prior over $\delta$ and $\pi$.  We place a Dirichlet prior over every next symbol probability, and assume that each next state given a state/symbol pair is drawn from a multinomial probability for that symbol, which also has a Dirichlet prior over it.  Formally:

\begin{eqnarray}
\mu|\gamma & \sim & \mathrm{Dir}\left(\gamma/|Q|,\ldots,\gamma/|Q|\right) \\
\phi_{j}|\alpha,\mathbf{\mu}  & \sim & \mathrm{Dir}(\alpha\mathbf{\mu}) \\
\pi_{i}|\beta & \sim & \mathrm{Dir}(\beta/|\Sigma|,\ldots,\beta/|\Sigma|)\\
\delta(q_i,s_j) & \sim & \phi_{j}
\end{eqnarray}

And from this we generate a sequence of $T$ symbols recursively:

\begin{eqnarray*}
q^0 & = & q_0 \\
x_0 & \sim & \pi^0 \\
q^t & = & \delta(q^{t-1},x_{t-1}) \\
x_t & \sim & \pi^t
\end{eqnarray*}

With likelihood

\[ p(x_{0:T}|\delta,\pi) = \pi(q^0,x_0)\prod_{t=1}^T \pi(q^t,x_t) \]

Thanks to Multinomial-Dirichlet conjugacy we can integrate out $\pi$, $\mu$ and $\phi$ and express the probability of a sequence given a transition function as follows:

\begin{eqnarray}
 p(x_{0:T}|\delta,\beta) & = & \int p(x_{0:T}|\pi,\delta) p(\pi|\beta) d\pi \\
 & = &  \int \prod_{j=1}^{|Q|} \frac{\Gamma(\beta)}{\Gamma(\frac{\beta}{|\Sigma|})^{|\Sigma|}} \gamma(q_j,s_1)^{\frac{\beta}{|\Sigma|}+c_{j1}-1} \gamma(q_j,s_2)^{\frac{\beta}{|\Sigma|}+c_{j2}-1} \ldots \gamma(q_j,s_{|\Sigma|})^{\frac{\beta}{|\Sigma|}+c_{j|\Sigma|}-1} \\
 & = & \prod_{j=1}^{|Q|} \frac{\Gamma(\beta)}{\Gamma(\frac{\beta}{|\Sigma|})^{|\Sigma|}} \frac{\prod_{i=1}^{|\Sigma|}\Gamma(\frac{\beta}{|\Sigma|} + c_{ji})}{\Gamma(\beta + \sum_{i=1}^{|\Sigma|} c_{ji})}
 \end{eqnarray}
 
 Where $c_{ji}$ is the number of times the symbol $s_i$ is emitted when in the state $q_j$.  
 
 For the transition matrix, the two-stage Dirichlet prior has the effect of tying together distributions over different columns.  This means that the state/symbol transitions are more similar for transitions from the same symbol, but are still shared across completely different state/symbol pairs.  As $|Q|\rightarrow\infty$, Equations 1 and 2 (*replace this with LaTeX equation titles*) have a well-defined limit as long as the number of observations is finite.  This is the Hierarchical Dirichlet Process.  In the case of posterior inference of $\delta$, when only a finite number of state/symbol pairs are visited by the data, we may integrate out all other elements of $\delta$, and the limit in the case of infinite states is well-defined.
 
We can sample incrementally from the joint distribution over $x_{0:T}$ and $\delta$ when $\phi_j$, $\mu$ and $\pi_i$ are integrated out in the $|Q|\rightarrow\infty$ limit.  From the start state $q_0$, we sample a symbol $s_{j_0}$ uniformly and assign $\delta_{0j_0}$ to a new state.  If $q^t = q_i$ then $x_t$ has the probability

 \[P(x_t=s_j|q_i,x_{0:t-1},q^{0:t-1}) = \frac{c_{ij}+\frac{\beta}{|\Sigma|}}{c_{i\cdot} + \beta}\]
 
 where $c_{ij}$ is the number of times so far $s_j$ was emitted from $q_i$ and $c_{i\cdot}$ is the total number of times $q_i$ has been visited so far.  
 
If the state/symbol pair $(q_i,s_j)$ has not been visited before, we have to sample $\delta_{ij}$.  The two-stage generative procedure for elements of $\delta$ means that we have to keep track of counts at two levels.  Each $\delta_{ij}$ belongs to a cluster $v_{kj}$ that contains other $\delta_{i'j}$, while each $v_{kj}$ belongs to a top-level cluster $w_{l}$ that has elements across all $j$.  Each top level cluster has one $q \in Q$ assigned to it, and $\delta_{ij}$ is equal to that $q$ in the top cluster that the cluster with $\delta_{ij}$ belongs to (*might want to make this part clearer...add a figure*).  Let $\delta^t$ denote the elements of $\delta$ that have been visited at time $t$.  as follows:
 
%\[P(\delta_{ij} = k|\delta^t) \propto \begin{cases} & if $k \le |\delta^t|$ \cr  & if $k > |\delta^t|$ \end{cases}\]
 
 This process for sampling from an HDP when $\mu$ and $\phi_j$ are integrated out is known as the {\em Chinese Restaurant Franchise Process}.