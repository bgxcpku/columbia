\documentclass[11pt]{article}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{A Nonparametric Bayesian Approach to PDFA Induction}
\author{David Pfau}
%\date{}                                           % Activate to display a given date or no date

\begin{document}
\maketitle

\begin{abstract}
We wish to learn minimally complex, maximally predictive models for finite alphabet sequence data.  To do this, we describe a nonparametric prior distribution over probabilistic deterministic finite automata and an MCMC algorithm for posterior inference.  We take the Bayesian perspective to avoid overfitting and escape local minima in the space of models.  In the limit of many samples, the posterior estimate has the same expressive power as a hidden Markov model, while retaining properties of a variable or fixed order Markov model that are attractive for predicting sequences.  We demonstrate the performance on natural language and DNA, achieving superior prediction rates to much larger models.
\end{abstract}

\section{Introduction}
All learning algorithms must strike a compromise between computational efficiency, model complexity and predictive accuracy.  In this paper we focus on optimizing the last two on the task of discrete sequence prediction.  In the extreme limit, the best solution would be to find the shortest computer program that can reproduce the data exactly, but this sacrifices computational efficiency to the point that it is incomputable.  Instead, we tackle the much more pragmatic problem of learning probabilistic deterministic finite automata (PDFA), a class of models that includes variable and fixed order Markov models as a special case, as well as simpler models.  At a high level, a PDFA can be thought of as a hidden Markov model for which, given an observed sequence, there is only one possible path through the hidden states.  A more formal definition follows in section 2.

We motivate our choice of model class several ways.  First, it can be shown by a simple argument that, given an infinite and stationary sequence, the minimal sufficient statistics of the past for predicting the future form a PDFA \cite{Crutchfield1999}.  That is, given two pasts that map to the same statistic, the concatenation of those pasts with the same symbol will map to the same statistic.  This is not the case in general hidden Markov models, where many transitions are possible from a hidden state, though observed data may change the posterior probability of those transitions.  Existing algorithms for learning these statistics use tests that have asymptotic guarantees but may not work well for reasonable amounts of data \cite{Shalizi2004}.

N-gram models have had great empirical success in sequence prediction.  However, there is no clear way to trade off model complexity with prediction accuracy.  In extensions to n-gram models which can learn from arbitrarily long contexts, the model complexity will grow without bound, even for trivially simple sequences such as repetitions of a few characters.  Bounded memory models perform well in practice, but we would much prefer to learn a model that is as small as possible for very simple data, while growing large for more complex data.  A natural class of models to explore is probabalistic deterministic finite automata (PDFA), which contains n-grams as a special case, as well as simpler models.  We define a prior over PDFAs with a finite number of states and describe a Metropolis-Hastings algorithm to generate samples from the posterior.  We then generalize to the case of PDFAs with a (potentially) infinite number of states and show that the generative model is a type of Hierarchical Dirichlet Process (HDP).  We then (I hope!) describe a state splitting/merging algorithm for posterior inference that mixes more efficiently than the original Metropolis-Hastings algorithm, and show that it defines a natural hierarchy of states for smoothing (fingers crossed...)  The set of strings produced by a PDFA constitutes a probabilistic regular language, thus our inference procedure can also be viewed as a non-greedy algorithm for regular grammar induction.

\section{Probabilistic Deterministic Finite Automata}
A PDFA is formally defined as a 5-tuple $M = (Q,\Sigma,\delta,\pi,q_0)$.  $Q$ is a finite set of states. $\Sigma$ is a finite alphabet of observable symbols. $\delta\,:\,Q\times\Sigma\rightarrow Q$ is the transition function from a state/symbol pair to the next state.  $\pi\,:\,Q\times\Sigma\rightarrow[0,1]$ is the probability of the next symbol given a state.  $q_0$ is the initial state.  For clarity and minimal clutter, we use $i$ to index over elements of $Q$, $j$ to index over elements of $\Sigma$ and $t$ to index elements of an observed string.  For example, $\delta_{ij}$ is shorthand for $\delta(q_i,s_j)$.

The odd-sounding ``probabilistic deterministic" refers to the fact that a string of symbols is generated by a two-stage process.  Given a state $q_i$, the probability that the next symbol is $s$ is given by $\pi(q_i,s)$, hence ``probabilistic."  We denote the multinomial distribution over symbols given a state $q_i$ as $\pi_i$, so we could equivalently say $s \sim \pi_i$.  Given a state $q_i$ and a symbol $s$, however, there is a {\it unique} state $\delta(q_i,s)$ that follows it, hence ``deterministic."  

We can see that n-grams or nth-order Markov models are a particular class of PDFAs.  If we consider a state to be the prefix $x_1 x_2 \ldots x_{n-1}$, then given a state and a symbol $x_n$, the unique next state is $x_2 \ldots x_n$.  Thus nth-order Markov models are a subclass of PDFAs with $|\Sigma|^n$ states.

PDFAs themselves are a subclass of hidden Markov models (HMMs).  Specifically, they are the class of HMMs for which, given a sequence of observed data, there is only one possible path through the hidden states.  Our approach to inference, taking posterior samples over the space of models, while forcing the path through these models to be deterministic, can be seen as an extreme case of the tradeoff inherent in most model learning.  Normally, one has to estimate both the model and the parameters of the model, but in this case all of the uncertainty is shifted onto the model itself.

\section{Previous Work}

Despite a wealth of research on both the theory and practice of learning PDFAs, the work presented here is, to our knowledge, the first algorithm to generate samples from a posterior over automata rather than returning a deterministic estimate.  Prior work has focused on greedy algorithms, which work by either merging or splitting elements of $Q$ according to some statistical test.  Theoretical work has shown that PDFAs are both identifiable in the limit and, with a few restrictions on the model class\footnote{A polynomial number of states in the true automata, a minimum divergence between the distribution over strings that follow two states, and a polynomial bound on the probability of generating strings above a certain length}, are also PAC-learnable\footnote{A model class is said to be {\em PAC-learnable} if there is an algorithm that will return, in time polynomial in $\frac{1}{\delta}$,$\frac{1}{\epsilon}$ and $|D|$, an estimate within an accuracy $\epsilon$ of the true model from $|D|$ examples with probability $1-\delta$.} using KL divergence between automata as a measure of accuracy.

\subsection{State Merging Algorithms}
A variety of algorithms work by starting with the trivial automata built from the prefix tree of the data, and generalizes by merging states that pass a similarity test.  Merging two states is not trivial: if $\delta(q_1,s_j) \ne \delta(q_2,s_j)$, then merging $q_1$ and $q_2$ will produce a state with nondeterministic transitions.  This is avoided by recursively merging the states $\delta_{1j}$ and $\delta_{2j}$ until the resulting automata is deterministic.  The result is a {\em quotient automata} of the original.  One of the earliest algorithms to use this method is ALERGIA \cite{Oncina1994}, which uses a test based on the Hoeffding bound to decide whether to merge states, and was proven to converge to the true automata in the limit of infinite data.

Later algorithms have mostly focused on improving the state merging test.  MDI uses a test based on the KL divergence between automata, and penalizes automata with many states.  Thus it can be interpreted as a greedy maximum posterior estimator with a minimum description length prior.  Empirically, it has better predictive performance than ALERGIA on natural language data.

\cite{Clark2004} presented a state-merging algorithm for cyclic PDFAs that is PAC-learnable given very few restrictions on the model class.  While the emphasis was on theoretical rather than empirical performance, it was also shown to work well from small data.

\subsection{State Splitting Algorithms}

State splitting algorithms, by contrast, start with the most general single-state automata and become more selective by adding more states.  \cite{Ron1995} learned a variable-order Markov model using a state-splitting algorithm, where a state corresponding to a string suffix was split into states corresponding to longer suffixes according to some test (*hm...all this "according to some test" is getting redundant.  Might want to rephrase this*).  Splitting might occasionally produce nondeterministic transitions.  For example, after splitting the context $01$ into $001$ and $101$, the context $0$ and symbol $1$ might transition to either one, unless the context $0$ is also split into $10$ and $00$, but these probabilistic suffix trees could be mapped onto PDFAs after learning.

CSSR \cite{Shalizi2004} took a similar approach, but with a model class that contains all PDFAs.  Their philosophical motivation, similar to ours, is to learn the minimal sufficient statistics for predicting the future given the past.  Given a stationary sequence with infinitely long past and future, those statistics form a PDFA, which they call a {\em causal state machine}.  Each state is a set of suffixes, rather than a single suffix, which means the model class includes all PDFAs.  If the predictive distribution for a suffix passes a Kolmogorov-Smirnov test, that state is split in two and suffixes in the original state are divided.  Nondeterministic transitions are removed recursively by backing up to the states preceding a split state and splitting in the natural way, much like the reverse of how states are merged when forming quotient automata.

\section{A Generative Model for PDFAs}

We assume that $Q$, $\Sigma$ and $q_0$ are known, and define a prior over $\delta$ and $\pi$.  We place a Dirichlet prior over every next symbol probability, and assume that each next state given a state/symbol pair is drawn from a multinomial probability for that symbol, which also has a Dirichlet prior over it.  Formally:

\begin{eqnarray}
\mu|\gamma & \sim & \mathrm{Dir}\left(\gamma/|Q|,\ldots,\gamma/|Q|\right) \\
\phi_{j}|\alpha,\mathbf{\mu}  & \sim & \mathrm{Dir}(\alpha\mathbf{\mu}) \\
\pi_{i}|\beta & \sim & \mathrm{Dir}(\beta/|\Sigma|,\ldots,\beta/|\Sigma|)\\
\delta(q_i,s_j) & \sim & \phi_{j}
\end{eqnarray}

And from this we generate a sequence of $T$ symbols recursively:

\begin{eqnarray*}
q^0 & = & q_0 \\
x_0 & \sim & \pi^0 \\
q^t & = & \delta(q^{t-1},x_{t-1}) \\
x_t & \sim & \pi^t
\end{eqnarray*}

With likelihood

\[ p(x_{0:T}|\delta,\pi) = \pi(q^0,x_0)\prod_{t=1}^T \pi(q^t,x_t) \]

Thanks to Multinomial-Dirichlet conjugacy we can integrate out $\pi$, $\mu$ and $\phi$ and express the probability of a sequence given a transition function as follows:

\begin{eqnarray}
 p(x_{0:T}|\delta,\beta) & = & \int p(x_{0:T}|\pi,\delta) p(\pi|\beta) d\pi \\
 & = &  \int \prod_{j=1}^{|Q|} \frac{\Gamma(\beta)}{\Gamma(\frac{\beta}{|\Sigma|})^{|\Sigma|}} \gamma(q_j,s_1)^{\frac{\beta}{|\Sigma|}+c_{j1}-1} \gamma(q_j,s_2)^{\frac{\beta}{|\Sigma|}+c_{j2}-1} \ldots \gamma(q_j,s_{|\Sigma|})^{\frac{\beta}{|\Sigma|}+c_{j|\Sigma|}-1} \\
 & = & \prod_{j=1}^{|Q|} \frac{\Gamma(\beta)}{\Gamma(\frac{\beta}{|\Sigma|})^{|\Sigma|}} \frac{\prod_{i=1}^{|\Sigma|}\Gamma(\frac{\beta}{|\Sigma|} + c_{ji})}{\Gamma(\beta + \sum_{i=1}^{|\Sigma|} c_{ji})}
 \end{eqnarray}
 
 Where $c_{ji}$ is the number of times the symbol $s_i$ is emitted when in the state $q_j$.  
 
 For the transition matrix, the two-stage Dirichlet prior has the effect of tying together distributions over different columns.  This means that the state/symbol transitions are more similar for transitions from the same symbol, but are still shared across completely different state/symbol pairs.  As $|Q|\rightarrow\infty$, Equations 1 and 2 (*replace this with LaTeX equation titles*) have a well-defined limit as long as the number of observations is finite.  This is the Hierarchical Dirichlet Process.  In the case of posterior inference of $\delta$, when only a finite number of state/symbol pairs are visited by the data, we may integrate out all other elements of $\delta$, and the limit in the case of infinite states is well-defined.
 
We can sample incrementally from the joint distribution over $x_{0:T}$ and $\delta$ when $\phi_j$, $\mu$ and $\pi_i$ are integrated out in the $|Q|\rightarrow\infty$ limit.  From the start state $q_0$, we sample a symbol $s_{j_0}$ uniformly and assign $\delta_{0j_0}$ to a new state.  If $q^t = q_i$ then $x_t$ has the probability

 \[P(x_t=s_j|q_i,x_{0:t-1},q^{0:t-1}) = \frac{c_{ij}+\frac{\beta}{|\Sigma|}}{c_{i\cdot} + \beta}\]
 
 where $c_{ij}$ is the number of times so far $s_j$ was emitted from $q_i$ and $c_{i\cdot}$ is the total number of times $q_i$ has been visited so far.  
 
If the state/symbol pair $(q_i,s_j)$ has not been visited before, we have to sample $\delta_{ij}$.  The two-stage generative procedure for elements of $\delta$ means that we have to keep track of counts at two levels.  Each $\delta_{ij}$ belongs to a cluster $v_{kj}$ that contains other $\delta_{i'j}$, while each $v_{kj}$ belongs to a top-level cluster $w_{l}$ that has elements across all $j$.  Each top level cluster has one $q \in Q$ assigned to it, and $\delta_{ij}$ is equal to that $q$ in the top cluster that the cluster with $\delta_{ij}$ belongs to (*might want to make this part clearer...add a figure*).  Let $\delta^t$ denote the elements of $\delta$ that have been visited at time $t$.  as follows:
 
\[P(\delta_{ij} = k|\delta^t) \propto \cases{ & if $k \le |\delta^t|$ \cr  & if $k > |\delta^t|$}\]
 
 This process for sampling from an HDP when $\mu$ and $\phi_j$ are integrated out is known as the {\em Chinese Restaurant Franchise Process}.
 
 \section{Posterior Inference over PDFAs}
 
 We perform posterior inference by sampling assignments for $\delta_{ij}$ individually.  Rather than ordinary Gibbs sampling, we use a mixed Gibbs/Metropolis-Hastings update.  To see why, consider the following case:  $\delta_{ij}$ is the only sampled element of $\delta$ that is assigned to the state $q_{i'}$.  When we removed $\delta_{ij}$ from the counts to sample it, the probability of assigning it back to $q_{i'}$ becomes zero, and even if it is assigned to some new state $q_{i''}$, the probability that $\delta_{i'j} = \delta_{i''j}$ for all $j$ visited by the data is low.  We do not want to forget a good sample, so instead we propose a new $\delta_{ij}$ and accept or reject according to the usual Metropolis-Hastings ratio.
 
Samples from the CRF are exchangeable, so we can remove $\delta_{ij}$ and propose a sample $\delta{ij}^*$ according to the CRF given $\delta_{-ij}^T$, the elements of $\delta$ visited by $x_{0:T}$ excluding $\delta_{ij}$.  This is the prior probability excluding the data, which cancels with the equivalent term in the posterior, meaning that the accept probability $\alpha(\delta_{ij},\delta_{ij}^*)$ is given by the ratio of the likelihood of the data

\[ \alpha(\delta_{ij},\delta_{ij}^*) =  \mathrm{min}\left(1,\frac{p(x_{0:T}|\delta_{ij}^*,\delta_{-ij}^T)}{p(x_{0:T}|\delta_{ij},\delta_{-ij}^T)}\right)\]

In general the numerator cannot be evaluated because changing $\delta_{ij}$ means changing the entire sequence of states visited by the data after $\delta_{ij}$ is first visited.  In practice we estimate the numerator by Monte Carlo approximation, sampling elements of $\delta$ according to the CRF as they are first visited by the data.  Changing one element of $\delta$ means many already-sampled state/symbol pairs may never be visited by the data, and have no effect on the likelihood.  The posterior probability of any value for these elements of $\delta$ is the same as the prior, and therefore we may remove them from $\delta^T$ after accepting a new $\delta_{ij}$.
 
 %Similarly, for a given transition matrix the probability is
 
% \[ p(\delta|\alpha) = \prod_{i=1}^{|\Sigma|} \frac{\Gamma(\alpha)}{\Gamma(\frac{\alpha}{|Q|})^{|Q|}} \frac{\prod_{j=1}^{|Q|}\Gamma(\frac{\alpha}{|Q|} + n_{ji})}{\Gamma(\alpha + |Q|)} \]
 
% Where $n_{ji}$ is the number of times the state $q_j$ appears in the $i$th column of the transition matrix.  Note that the counts $n_{ji}$ depend only on the transition matrix $\delta$ while the counts $c_{ji}$ depend on both $\delta$ and the data.  From this we can construct a Gibbs sampler for the next state transition matrix.  The conditional probability of one entry in the transition matrix is given below.  We write $\delta(q_j,s_i)$ as $\delta_{ji}$ for compactness, and write the rest of the matrix as $\delta_{-ji}$ .
 
 %\[ p(\delta_{ji} = q_k | \delta_{-ji},x_{0:T},\alpha,\beta) \propto p(x_{0:T}|\delta_{ji}=q_k,\delta_{-ji},\beta) p(\delta_{ji}=q_k,\delta_{-ji}|\alpha) \]

%The case of smoothed n-gram models is more complicated.  Smoothing works by considering more general contexts for which we have more observations.  In the case of an n-gram model, this would correspond to prefixes with fewer than $n-1$ characters.  For example, the predictive distribution given $xy$ is smoothed by the distribution given $y$, which is smoothed by the distribution given no context.  From the DFA point of view, these contexts can be seen as transient states: once we observe more than $n-1$ characters of a sequence, every prefix will be long enough to uniquely assign it to some recurrent state (In the example above, we only observe the null context at the very beginning of a string, and the context $y$ one character into a string).  Thus the way to strengthen the predictive power of learned DFAs is to smooth recurrent states by corresponding transient states.  I haven't yet figured out how to identify which transient states go with which recurrent states, but there is no reason to think it would be infeasible.  I should note, tying together states in this way would go above and beyond Causal State Splitting Reconstruction.  CSSR does not tie predictive distributions together, and simply discards transient states.

%\subsection{}



\end{document}  